[Settings]
cpp_model_path = 
exllama_model_path = 

[Params-Shared]
temperature = 0.95
top_k = 20
top_p = 0.65
max_new_tokens = 256
repetition_penalty = 1.15
seed = -1

[Params-Exllama]
min_p = 0
token_repetition_penalty_decay = 256
num_beams = 1
beam_length = 1

[Params-LlamaCPP]
threads = 4
context_size = 2048
repeat_last_n = 64
batch_size = 512
mirostat_mode = 0
n_gpu_layers = 22
lora_path = 
use_mmap = True
use_mlock = False
use_gpu_accel = True