[Settings]
cpp_model_path = /mnt/ext4_data0/gits/llama.cpp/models/tulu-7b.ggmlv3.q5_K_S.bin
exllama_model_path = /run/media/pigeondave/ntfsgames/_LLM/oobabooga-windows/text-generation-webui/models/TheBloke_WizardLM-7B-uncensored-GPTQ
rwkv_cpp_model_path = /mnt/ext4_data0/gits/rwkv.cpp/q4_0-RWKV-4-Raven-7B-v12-Eng98-Other2-20230521-ctx8192.bin
user_name = User
bot_name = Assistant
backend = exllama
theme = dark

[Params-Shared]
temperature = 0.95
top_k = 20
top_p = 0.65
max_new_tokens = 256
repetition_penalty = 1.15
seed = -1

[Params-Exllama]
min_p = 0
token_repetition_penalty_decay = 256
num_beams = 1
beam_length = 1
gpu_split = False
gpu_split_values = 

[Params-LlamaCPP]
threads = 4
context_size = 2048
tfs_z = 1.0
batch_size = 512
mirostat_mode = 0
n_gpu_layers = 22
lora_path = 
frequency_penalty = 0.0
presence_penalty = 0.0
use_mmap = True
use_mlock = False
use_gpu_accel = True
use_cache = True
use_verbose = False

[Params-TextSynth]
ts_model = 

